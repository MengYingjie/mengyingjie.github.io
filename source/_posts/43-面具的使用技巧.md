---
title: 🎭面具的使用技巧
tags:
  - ChatGPT
  - AI
date: 2025-01-05 03:51:15
categories:
  - AIGC
---

> [⭐ 孟应杰的网站: myj.im ⭐](https://myj.im/)


# 简介

使用[NextChat网页应用(ChatGPT Next Web)](https://github.com/ChatGPTNextWeb/NextChat)设置预设对话建立Few-Shot面具，更精准更快捷地使用AI-Chat工具。


# 面具示例汇总

方便第二次阅读使用，第一次阅读可以先看下面具制作过程。

|         |          |        |      |
| ------- | -------- | ------ | ---- |
| 输出      | 输出       | 实现路径指南 | 面具示例 |
| HLD需求分析 | LLD第一章   |        |      |
| API接口描述 | TP用例     |        |      |
| 伪代码     | 代码       |        |      |
| TP      | Python脚本 |        |      |
| TP      | RF脚本     |        |      |


# Zero-Shot与Few-Shot

## Zero-Shot

在 Few-shot 这个概念之上还有一个 Zero-Shot，所以我们先了简单解一下 Zero-Shot

Zero-Shot Prompting 是一种自然语言处理技术，可以让计算机模型根据提示或指令进行任务处理。ChatGPT 就用到这个技术。

举个例子，我们可以给 ChatGPT 一个简短的 prompt，比如给出某部电影的名称，它就可以生成一个关于该情节的摘要，而不需要进行电影相关的专门训练。 -- 引用自 **[Zero-Shot](https://learningprompt.wiki/docs/tutorial-extras/Zero-Shot%20Prompts)**

Zero-Shot 的优点是方便快捷、发散思维，我不需要给他任何提示，直接就开聊。这也同时是他的缺点，每次相同的提问，极有可能会给你不同的答案。我们可以利用Zero-Shot来进行思维的扩展，例如**技术交流****、****LLD****的设计考虑、代码分析、BUG解决**等。

## Few-Shot

可以把 Few-Shot 简单理解为，让模型回答问题之前先给它几个**一问一答**的例子（有助于 AI 进行**链式****思维**以提升结果的准确率）。之后你再问相关的问题它就会根据你提供的例子进行规范作答。这就像是一个超级 mini 的 Fine-tuning，由于 GPT 3.5 模型过于强大，我们只需用几个小例子即可得到很好的效果。

通过 Few-shot 制作面具，引导模型返回更符合我们预期的答案，使ChatGPT成为一个生产力工具，例如**TP生成、****LLD****格式生成、代码生成、****自动化脚本**生成等工具。

> 深入了解 Few-Shot请参考：[参考连接1](https://learningprompt.wiki/docs/tutorial-extras/Few-Shot%20Prompting)，[参考连接2](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md#few-shot-examples)


# 使用Few-Shot制作面具

区别于我们原来的面具制作，原来的面具（或者提示词）制作全是以用户角度的输入，很难达到训练AI的效果，他只会根据我们的输入内容进行发散回答，导致回答内容很难符合我们的预期。我们以TP生成自动化脚本为例描述面具的制作。

## 新建一个面具并设置前置上下文

点击：面具-查看全部-新建

![](1182f70ca6531857175a276bf1b4f2bb_MD5.png)

## 设置合适的角色和prompt

前置对话角色描述：

|   |   |
|---|---|
|system|system 角色定义了 assistant 的主要行为|
|user|用户所代表的角色|
|assistant|GPT所代表的角色|

以TP生成脚本示例设置提示词：

![](18a97818680096f1f60c954cb6f386dd_MD5.png)

这里我使用了 1 shot（一个 user + assistant 的问答即 1 shot）来创建这个面具，其中 system 角色定义了 assistant 的主要行为，也就是让模型大概知道它自己是干啥的。后面的 user + assistant prompt 让模型参考应该以何种方式回答问题。指定面具时可以根据需要多设定几个shot。

具体内容如下：

|           |                                                                                                                                                                                                                     |
| --------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| system    | 你现在是Python专家，我需要你根据我的测试用例编写测试脚本，我会给你提供测试用例，你需要严格按照我的TP用例生成代码。                                                                                                                                                       |
| user      | TP用例用例如下：<br><br>用例名称：<br><br>云防火墙规则创建、查询、删除（硬墙）<br><br>用例步骤：<br><br>1、构造基础环境<br><br>2、在net_s1下创建port，device_owner为DEVICE_OWNER_VM<br><br>【省略】<br><br>用例期望：<br><br>1、构建成功<br><br>2、大带宽防火墙上有配置：router1配置<br><br>【省略】 |
| assistant | 我根据你提供TP，生成自动化脚本，以下是测试用例的脚本代码：<br><br>def run_case(): 【省略】                                                                                                                                                          |


## 附带历史消息数设置为 0

在使用该工具之前，需要先将设置里的附带历史消息数设置为 0，否则消息历史会对之前做的 Few-shot 产生影响。（因为AI是**链式****思维**）

![](910ba56bc046516ca2eca596131ff90e_MD5.png)


## 使用面具

开始对话

![](785aec667de7b8ddc47745f30372f7b0_MD5.png)

输入新的TP脚本

![](d8c30fb32cfaf40eed9a2591525beedc_MD5.png)

GPT输出：

经循环测试，每次输出结果都基本一致，脚本可用度比较高。

![](b7deb45977cb823eec3fc164f62a5866_MD5.png)


## 两次面具的对比

原来的前置对话是这个样子的：

![](2c570ef6ed5d5c7cad6e9ba5327a3e56_MD5.png)

现在的前置对话是这样子的：

![](1a70270c8c5728677ee3763b55c99bc1_MD5.png)